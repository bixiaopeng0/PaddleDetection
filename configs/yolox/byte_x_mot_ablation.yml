_BASE_: [
  '../datasets/coco_detection.yml',
  '../runtime.yml',
  './_base_/yolox_cspdarknet.yml',
  './_base_/optimizer_300e.yml',
  './_base_/yolox_reader.yml',
]
pretrain_weights: https://paddledet.bj.bcebos.com/models/mot/yolox/torch2paddle_final_yolox/yolox_x_coco_paddle_rgb.pdparams

snapshot_epoch: 2
weights: output/byte_x_mot_ablation/model_final

depth_factor: 1.33
width_factor: 1.25

metric: COCO
num_classes: 1

##### model
YOLOX:
  backbone: CSPDarkNet
  neck: YOLOCSPPAN
  yolox_head: YOLOXHead
  post_process: YOLOXPostProcess2

YOLOXHead:
  strides: [8, 16, 32]
  channels: [256, 512, 1024]
  depthwise: False
  mosaic_epoch: 70
  yolox_loss: YOLOXLoss

YOLOXPostProcess2: # slow but more accurate
  conf_thres: 0.01
  decode:
    name: YOLOXBox
  nms:
    name: MultiClassNMS
    nms_top_k: 30000
    keep_top_k: 1000
    score_threshold: 0.01
    nms_threshold: 0.7
    return_index: true

YOLOXPostProcess:
  decode:
    name: YOLOXBox
  nms:
    name: MultiClassNMS
    nms_top_k: 30000
    keep_top_k: 1000
    score_threshold: 0.01 ###
    nms_threshold: 0.7
    return_index: true

##### optimizer
epoch: 80
LearningRate:
  base_lr: 0.01
  schedulers:
  - !YOLOXCosineDecay
    max_epochs: 80
    no_aug_epochs: 10
    min_lr_ratio: 0.05
  - !ExpWarmup
    start_lr: 0.
    warmup_epochs: 5

OptimizerBuilder: # no use now
  optimizer:
    momentum: 0.9
    type: Momentum
    use_nesterov: true
    #param_groups:
    #  - params: ['bias', 'bn']
    #    weight_decay: 0.
  regularizer:
    factor: 0.0005
    type: L2

##### reader: bytetrack use legacy YOLOX, can remove all NormalizeImage
worker_num: 0 #4
TrainReader:
  inputs_def:
    num_max_boxes: 120
  sample_transforms:
    - DecodeResize: {target_size: [800, 1440], keep_ratio: True, hsv_prob: 1.0, flip_prob: 0.5, fill_value: 114}
    - YOLOXMosaic: {prob: 1.0, degrees: 10.0, translate: 0.1, scale: [0.1, 2], shear: 2.0, perspective: 0.0, input_dim: [800, 1440]}
  batch_transforms:
    - RecBatchRandomResize: {input_size: [800, 1440], random_size_factor: [18, 26]}
    #- RecBatchRandomResize: {input_size: [800, 1440], random_size_factor: [18, 32]}
    - PadBox: {num_max_boxes: 120}
    - Permute: {}
  batch_size: 2 #8
  shuffle: False #True
  drop_last: True
  collate_batch: True 
  use_shared_memory: True
  mosaic_epoch: 70
  mosaic_sample_num: 5

EvalReader:
  sample_transforms:
    - DecodeResize: {target_size: [800, 1440], keep_ratio: True, fill_value: 114}
    #- DecodeResize: {target_size: [800, 1440], keep_ratio: True, legacy: True, fill_value: 114}
    #- NormalizeImage: {is_scale: true, mean: [0.485, 0.456, 0.406], std: [0.229, 0.224, 0.225]}
  batch_transforms:
    - Permute: {}
  batch_size: 1

TestReader:
  inputs_def:
    image_shape: [3, 800, 1440]
  sample_transforms:
    - DecodeResize: {target_size: [800, 1440], keep_ratio: True, legacy: True, fill_value: 114}
    #- NormalizeImage: {is_scale: true, mean: [0.485, 0.456, 0.406], std: [0.229, 0.224, 0.225]}
  batch_transforms:
    - Permute: {}
  batch_size: 1

TestReader0: # old
  inputs_def:
    image_shape: [3, 800, 800]
  sample_transforms:
    - Decode: {}
    - Resize: {target_size: [800, 1440], keep_ratio: True, interp: 2}
    - SquareImage: {fill_value: 114, is_channel_first: false, target_size: [800, 1440]}
    #- NormalizeImage: {is_scale: true, mean: [0.485, 0.456, 0.406], std: [0.229, 0.224, 0.225]}
  batch_transforms:
    - Permute: {}
  batch_size: 1


###### data
TrainDataset:
  !COCODataSet
    image_dir: train
    anno_path: annotations/train_half.json
    dataset_dir: dataset/MOT
    data_fields: ['image', 'gt_bbox', 'gt_class', 'is_crowd']

EvalDataset:
  !COCODataSet
    image_dir: train
    anno_path: annotations/val_im2.json
    dataset_dir: dataset/MOT

TestDataset:
  !ImageFolder
    anno_path: annotations/val_half.json
